{
  "best_global_step": 5202,
  "best_metric": 86.63485416313397,
  "best_model_checkpoint": "./mt5-hindi-gec-model-fixed\\checkpoint-5202",
  "epoch": 7.0,
  "eval_steps": 500,
  "global_step": 6069,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.05772005772005772,
      "grad_norm": 1445.993896484375,
      "learning_rate": 3.530259365994237e-05,
      "loss": 21.7324,
      "step": 50
    },
    {
      "epoch": 0.11544011544011544,
      "grad_norm": 688.9669189453125,
      "learning_rate": 7.132564841498559e-05,
      "loss": 13.5786,
      "step": 100
    },
    {
      "epoch": 0.17316017316017315,
      "grad_norm": 67.39044952392578,
      "learning_rate": 0.00010734870317002881,
      "loss": 6.6404,
      "step": 150
    },
    {
      "epoch": 0.23088023088023088,
      "grad_norm": 6.728146076202393,
      "learning_rate": 0.00014337175792507203,
      "loss": 2.67,
      "step": 200
    },
    {
      "epoch": 0.2886002886002886,
      "grad_norm": 4.622528553009033,
      "learning_rate": 0.0001793948126801153,
      "loss": 1.4071,
      "step": 250
    },
    {
      "epoch": 0.3463203463203463,
      "grad_norm": 4.151945114135742,
      "learning_rate": 0.0002154178674351585,
      "loss": 1.0015,
      "step": 300
    },
    {
      "epoch": 0.40404040404040403,
      "grad_norm": 3.22206711769104,
      "learning_rate": 0.00025144092219020177,
      "loss": 0.8358,
      "step": 350
    },
    {
      "epoch": 0.46176046176046176,
      "grad_norm": 3.3099541664123535,
      "learning_rate": 0.000287463976945245,
      "loss": 0.6209,
      "step": 400
    },
    {
      "epoch": 0.5194805194805194,
      "grad_norm": 2.343860626220703,
      "learning_rate": 0.0003234870317002882,
      "loss": 0.5266,
      "step": 450
    },
    {
      "epoch": 0.5772005772005772,
      "grad_norm": 2.791306734085083,
      "learning_rate": 0.0003595100864553314,
      "loss": 0.4676,
      "step": 500
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 3.637192487716675,
      "learning_rate": 0.00039553314121037466,
      "loss": 0.4419,
      "step": 550
    },
    {
      "epoch": 0.6926406926406926,
      "grad_norm": 2.103614568710327,
      "learning_rate": 0.0004315561959654179,
      "loss": 0.3904,
      "step": 600
    },
    {
      "epoch": 0.7503607503607503,
      "grad_norm": 1.7832549810409546,
      "learning_rate": 0.0004675792507204611,
      "loss": 0.4039,
      "step": 650
    },
    {
      "epoch": 0.8080808080808081,
      "grad_norm": 2.184518337249756,
      "learning_rate": 0.0004995994873438001,
      "loss": 0.3919,
      "step": 700
    },
    {
      "epoch": 0.8658008658008658,
      "grad_norm": 1.5213866233825684,
      "learning_rate": 0.0004955943607818007,
      "loss": 0.3426,
      "step": 750
    },
    {
      "epoch": 0.9235209235209235,
      "grad_norm": 1.5541378259658813,
      "learning_rate": 0.0004915892342198014,
      "loss": 0.3398,
      "step": 800
    },
    {
      "epoch": 0.9812409812409812,
      "grad_norm": 2.983751058578491,
      "learning_rate": 0.000487584107657802,
      "loss": 0.3295,
      "step": 850
    },
    {
      "epoch": 1.0,
      "eval_gleu": 82.78899358331137,
      "eval_loss": 1.2172719240188599,
      "eval_runtime": 42.9165,
      "eval_samples_per_second": 2.493,
      "eval_steps_per_second": 0.326,
      "step": 867
    },
    {
      "epoch": 1.0380952380952382,
      "grad_norm": 2.0824015140533447,
      "learning_rate": 0.0004835789810958026,
      "loss": 0.3251,
      "step": 900
    },
    {
      "epoch": 1.0958152958152958,
      "grad_norm": 1.5368772745132446,
      "learning_rate": 0.00047957385453380327,
      "loss": 0.2967,
      "step": 950
    },
    {
      "epoch": 1.1535353535353536,
      "grad_norm": 1.3417431116104126,
      "learning_rate": 0.0004755687279718039,
      "loss": 0.2904,
      "step": 1000
    },
    {
      "epoch": 1.2112554112554113,
      "grad_norm": 2.445751667022705,
      "learning_rate": 0.00047156360140980454,
      "loss": 0.3005,
      "step": 1050
    },
    {
      "epoch": 1.2689754689754689,
      "grad_norm": 1.4214895963668823,
      "learning_rate": 0.00046755847484780525,
      "loss": 0.2923,
      "step": 1100
    },
    {
      "epoch": 1.3266955266955267,
      "grad_norm": 1.2750883102416992,
      "learning_rate": 0.00046355334828580586,
      "loss": 0.2704,
      "step": 1150
    },
    {
      "epoch": 1.3844155844155845,
      "grad_norm": 2.0044140815734863,
      "learning_rate": 0.0004595482217238065,
      "loss": 0.2682,
      "step": 1200
    },
    {
      "epoch": 1.4421356421356422,
      "grad_norm": 1.2109780311584473,
      "learning_rate": 0.00045554309516180713,
      "loss": 0.2638,
      "step": 1250
    },
    {
      "epoch": 1.4998556998556998,
      "grad_norm": 2.1719188690185547,
      "learning_rate": 0.0004515379685998078,
      "loss": 0.2911,
      "step": 1300
    },
    {
      "epoch": 1.5575757575757576,
      "grad_norm": 0.6406683325767517,
      "learning_rate": 0.0004475328420378084,
      "loss": 0.2714,
      "step": 1350
    },
    {
      "epoch": 1.6152958152958155,
      "grad_norm": 1.9088376760482788,
      "learning_rate": 0.00044352771547580906,
      "loss": 0.2655,
      "step": 1400
    },
    {
      "epoch": 1.673015873015873,
      "grad_norm": 0.9529935121536255,
      "learning_rate": 0.00043952258891380967,
      "loss": 0.2413,
      "step": 1450
    },
    {
      "epoch": 1.7307359307359307,
      "grad_norm": 1.276224970817566,
      "learning_rate": 0.00043551746235181033,
      "loss": 0.2676,
      "step": 1500
    },
    {
      "epoch": 1.7884559884559885,
      "grad_norm": 1.6487748622894287,
      "learning_rate": 0.000431512335789811,
      "loss": 0.244,
      "step": 1550
    },
    {
      "epoch": 1.8461760461760461,
      "grad_norm": 1.6287717819213867,
      "learning_rate": 0.0004275072092278116,
      "loss": 0.2516,
      "step": 1600
    },
    {
      "epoch": 1.9038961038961038,
      "grad_norm": 1.073131799697876,
      "learning_rate": 0.00042350208266581226,
      "loss": 0.2603,
      "step": 1650
    },
    {
      "epoch": 1.9616161616161616,
      "grad_norm": 1.069132924079895,
      "learning_rate": 0.00041949695610381287,
      "loss": 0.2427,
      "step": 1700
    },
    {
      "epoch": 2.0,
      "eval_gleu": 84.81598296968174,
      "eval_loss": 1.0006601810455322,
      "eval_runtime": 33.6753,
      "eval_samples_per_second": 3.177,
      "eval_steps_per_second": 0.416,
      "step": 1734
    },
    {
      "epoch": 2.0184704184704185,
      "grad_norm": 1.4992784261703491,
      "learning_rate": 0.00041549182954181353,
      "loss": 0.2179,
      "step": 1750
    },
    {
      "epoch": 2.0761904761904764,
      "grad_norm": 1.2570117712020874,
      "learning_rate": 0.00041148670297981414,
      "loss": 0.2171,
      "step": 1800
    },
    {
      "epoch": 2.1339105339105338,
      "grad_norm": 0.5362040400505066,
      "learning_rate": 0.0004074815764178148,
      "loss": 0.2152,
      "step": 1850
    },
    {
      "epoch": 2.1916305916305916,
      "grad_norm": 1.7293169498443604,
      "learning_rate": 0.00040347644985581546,
      "loss": 0.2106,
      "step": 1900
    },
    {
      "epoch": 2.2493506493506494,
      "grad_norm": 0.6992501616477966,
      "learning_rate": 0.00039947132329381607,
      "loss": 0.2186,
      "step": 1950
    },
    {
      "epoch": 2.3070707070707073,
      "grad_norm": 0.49102792143821716,
      "learning_rate": 0.00039546619673181673,
      "loss": 0.2239,
      "step": 2000
    },
    {
      "epoch": 2.3647907647907647,
      "grad_norm": 1.3092820644378662,
      "learning_rate": 0.00039146107016981734,
      "loss": 0.2184,
      "step": 2050
    },
    {
      "epoch": 2.4225108225108225,
      "grad_norm": 0.8084585070610046,
      "learning_rate": 0.000387455943607818,
      "loss": 0.2144,
      "step": 2100
    },
    {
      "epoch": 2.4802308802308803,
      "grad_norm": 1.3833363056182861,
      "learning_rate": 0.0003834508170458186,
      "loss": 0.1931,
      "step": 2150
    },
    {
      "epoch": 2.5379509379509377,
      "grad_norm": 0.8395264148712158,
      "learning_rate": 0.0003794456904838193,
      "loss": 0.2036,
      "step": 2200
    },
    {
      "epoch": 2.5956709956709956,
      "grad_norm": 0.7648599147796631,
      "learning_rate": 0.00037544056392181994,
      "loss": 0.1966,
      "step": 2250
    },
    {
      "epoch": 2.6533910533910534,
      "grad_norm": 0.4470295310020447,
      "learning_rate": 0.0003714354373598206,
      "loss": 0.2022,
      "step": 2300
    },
    {
      "epoch": 2.7111111111111112,
      "grad_norm": 1.5785061120986938,
      "learning_rate": 0.00036743031079782126,
      "loss": 0.1988,
      "step": 2350
    },
    {
      "epoch": 2.768831168831169,
      "grad_norm": 0.706142008304596,
      "learning_rate": 0.00036342518423582187,
      "loss": 0.1994,
      "step": 2400
    },
    {
      "epoch": 2.8265512265512265,
      "grad_norm": 0.6881361603736877,
      "learning_rate": 0.00035942005767382253,
      "loss": 0.1971,
      "step": 2450
    },
    {
      "epoch": 2.8842712842712843,
      "grad_norm": 0.5010467171669006,
      "learning_rate": 0.00035541493111182314,
      "loss": 0.2037,
      "step": 2500
    },
    {
      "epoch": 2.941991341991342,
      "grad_norm": 0.5105521082878113,
      "learning_rate": 0.0003514098045498238,
      "loss": 0.1987,
      "step": 2550
    },
    {
      "epoch": 2.9997113997113996,
      "grad_norm": 0.6000372171401978,
      "learning_rate": 0.00034740467798782446,
      "loss": 0.2131,
      "step": 2600
    },
    {
      "epoch": 3.0,
      "eval_gleu": 85.8423285625038,
      "eval_loss": 0.8913552165031433,
      "eval_runtime": 32.882,
      "eval_samples_per_second": 3.254,
      "eval_steps_per_second": 0.426,
      "step": 2601
    },
    {
      "epoch": 3.0565656565656565,
      "grad_norm": 0.5794215798377991,
      "learning_rate": 0.00034339955142582507,
      "loss": 0.1816,
      "step": 2650
    },
    {
      "epoch": 3.1142857142857143,
      "grad_norm": 0.7716043591499329,
      "learning_rate": 0.00033939442486382573,
      "loss": 0.1707,
      "step": 2700
    },
    {
      "epoch": 3.172005772005772,
      "grad_norm": 0.41090166568756104,
      "learning_rate": 0.00033538929830182634,
      "loss": 0.1782,
      "step": 2750
    },
    {
      "epoch": 3.2297258297258296,
      "grad_norm": 1.0464760065078735,
      "learning_rate": 0.000331384171739827,
      "loss": 0.1989,
      "step": 2800
    },
    {
      "epoch": 3.2874458874458874,
      "grad_norm": 0.812816321849823,
      "learning_rate": 0.0003273790451778276,
      "loss": 0.1792,
      "step": 2850
    },
    {
      "epoch": 3.3451659451659452,
      "grad_norm": 0.8567902445793152,
      "learning_rate": 0.00032337391861582827,
      "loss": 0.1655,
      "step": 2900
    },
    {
      "epoch": 3.402886002886003,
      "grad_norm": 0.7736676335334778,
      "learning_rate": 0.0003193687920538289,
      "loss": 0.1781,
      "step": 2950
    },
    {
      "epoch": 3.4606060606060605,
      "grad_norm": 0.38397619128227234,
      "learning_rate": 0.00031536366549182954,
      "loss": 0.1778,
      "step": 3000
    },
    {
      "epoch": 3.5183261183261183,
      "grad_norm": 0.5616316199302673,
      "learning_rate": 0.0003113585389298302,
      "loss": 0.1686,
      "step": 3050
    },
    {
      "epoch": 3.576046176046176,
      "grad_norm": 0.5027839541435242,
      "learning_rate": 0.0003073534123678308,
      "loss": 0.1828,
      "step": 3100
    },
    {
      "epoch": 3.6337662337662335,
      "grad_norm": 1.593043327331543,
      "learning_rate": 0.00030334828580583147,
      "loss": 0.1692,
      "step": 3150
    },
    {
      "epoch": 3.6914862914862914,
      "grad_norm": 1.3363040685653687,
      "learning_rate": 0.0002993431592438321,
      "loss": 0.176,
      "step": 3200
    },
    {
      "epoch": 3.749206349206349,
      "grad_norm": 0.6231033802032471,
      "learning_rate": 0.00029533803268183274,
      "loss": 0.1651,
      "step": 3250
    },
    {
      "epoch": 3.806926406926407,
      "grad_norm": 0.4852191209793091,
      "learning_rate": 0.00029133290611983335,
      "loss": 0.1667,
      "step": 3300
    },
    {
      "epoch": 3.864646464646465,
      "grad_norm": 0.8461764454841614,
      "learning_rate": 0.000287327779557834,
      "loss": 0.173,
      "step": 3350
    },
    {
      "epoch": 3.9223665223665223,
      "grad_norm": 1.41158127784729,
      "learning_rate": 0.0002833226529958347,
      "loss": 0.1857,
      "step": 3400
    },
    {
      "epoch": 3.98008658008658,
      "grad_norm": 0.5298967361450195,
      "learning_rate": 0.0002793175264338353,
      "loss": 0.1879,
      "step": 3450
    },
    {
      "epoch": 4.0,
      "eval_gleu": 86.41571669370688,
      "eval_loss": 0.8176417946815491,
      "eval_runtime": 31.0915,
      "eval_samples_per_second": 3.441,
      "eval_steps_per_second": 0.45,
      "step": 3468
    },
    {
      "epoch": 4.036940836940837,
      "grad_norm": 0.8089311718940735,
      "learning_rate": 0.000275312399871836,
      "loss": 0.1586,
      "step": 3500
    },
    {
      "epoch": 4.094660894660895,
      "grad_norm": 0.6000036597251892,
      "learning_rate": 0.0002713072733098366,
      "loss": 0.1485,
      "step": 3550
    },
    {
      "epoch": 4.152380952380953,
      "grad_norm": 0.5659306049346924,
      "learning_rate": 0.00026730214674783727,
      "loss": 0.1488,
      "step": 3600
    },
    {
      "epoch": 4.21010101010101,
      "grad_norm": 0.35740429162979126,
      "learning_rate": 0.0002632970201858379,
      "loss": 0.1469,
      "step": 3650
    },
    {
      "epoch": 4.2678210678210675,
      "grad_norm": 0.47863465547561646,
      "learning_rate": 0.00025929189362383854,
      "loss": 0.1569,
      "step": 3700
    },
    {
      "epoch": 4.325541125541125,
      "grad_norm": 0.6578899025917053,
      "learning_rate": 0.0002552867670618392,
      "loss": 0.1467,
      "step": 3750
    },
    {
      "epoch": 4.383261183261183,
      "grad_norm": 0.32915180921554565,
      "learning_rate": 0.0002512816404998398,
      "loss": 0.155,
      "step": 3800
    },
    {
      "epoch": 4.440981240981241,
      "grad_norm": 0.41802820563316345,
      "learning_rate": 0.00024727651393784047,
      "loss": 0.1573,
      "step": 3850
    },
    {
      "epoch": 4.498701298701299,
      "grad_norm": 0.4826088845729828,
      "learning_rate": 0.0002432713873758411,
      "loss": 0.1519,
      "step": 3900
    },
    {
      "epoch": 4.556421356421357,
      "grad_norm": 0.3289892077445984,
      "learning_rate": 0.00023926626081384174,
      "loss": 0.1478,
      "step": 3950
    },
    {
      "epoch": 4.6141414141414145,
      "grad_norm": 0.4096195101737976,
      "learning_rate": 0.00023526113425184237,
      "loss": 0.1593,
      "step": 4000
    },
    {
      "epoch": 4.6718614718614715,
      "grad_norm": 0.5654338598251343,
      "learning_rate": 0.000231256007689843,
      "loss": 0.1475,
      "step": 4050
    },
    {
      "epoch": 4.729581529581529,
      "grad_norm": 0.3725319802761078,
      "learning_rate": 0.00022725088112784364,
      "loss": 0.1559,
      "step": 4100
    },
    {
      "epoch": 4.787301587301587,
      "grad_norm": 1.1414451599121094,
      "learning_rate": 0.00022324575456584428,
      "loss": 0.1653,
      "step": 4150
    },
    {
      "epoch": 4.845021645021645,
      "grad_norm": 0.5154574513435364,
      "learning_rate": 0.0002192406280038449,
      "loss": 0.1559,
      "step": 4200
    },
    {
      "epoch": 4.902741702741703,
      "grad_norm": 0.5455023646354675,
      "learning_rate": 0.00021523550144184555,
      "loss": 0.1468,
      "step": 4250
    },
    {
      "epoch": 4.960461760461761,
      "grad_norm": 0.4124583303928375,
      "learning_rate": 0.0002112303748798462,
      "loss": 0.1538,
      "step": 4300
    },
    {
      "epoch": 5.0,
      "eval_gleu": 86.31537135896292,
      "eval_loss": 0.8837117552757263,
      "eval_runtime": 31.1486,
      "eval_samples_per_second": 3.435,
      "eval_steps_per_second": 0.449,
      "step": 4335
    },
    {
      "epoch": 5.017316017316017,
      "grad_norm": 0.526087760925293,
      "learning_rate": 0.00020722524831784684,
      "loss": 0.1443,
      "step": 4350
    },
    {
      "epoch": 5.075036075036075,
      "grad_norm": 0.738023042678833,
      "learning_rate": 0.00020322012175584748,
      "loss": 0.1341,
      "step": 4400
    },
    {
      "epoch": 5.132756132756133,
      "grad_norm": 0.3373394310474396,
      "learning_rate": 0.00019921499519384814,
      "loss": 0.1408,
      "step": 4450
    },
    {
      "epoch": 5.190476190476191,
      "grad_norm": 0.5201672315597534,
      "learning_rate": 0.00019520986863184878,
      "loss": 0.1488,
      "step": 4500
    },
    {
      "epoch": 5.2481962481962485,
      "grad_norm": 0.4635043740272522,
      "learning_rate": 0.0001912047420698494,
      "loss": 0.1398,
      "step": 4550
    },
    {
      "epoch": 5.3059163059163055,
      "grad_norm": 0.506023108959198,
      "learning_rate": 0.00018719961550785005,
      "loss": 0.1438,
      "step": 4600
    },
    {
      "epoch": 5.363636363636363,
      "grad_norm": 1.2046875953674316,
      "learning_rate": 0.0001831944889458507,
      "loss": 0.1298,
      "step": 4650
    },
    {
      "epoch": 5.421356421356421,
      "grad_norm": 0.5107424259185791,
      "learning_rate": 0.00017918936238385134,
      "loss": 0.1437,
      "step": 4700
    },
    {
      "epoch": 5.479076479076479,
      "grad_norm": 0.5392523407936096,
      "learning_rate": 0.00017518423582185198,
      "loss": 0.1315,
      "step": 4750
    },
    {
      "epoch": 5.536796536796537,
      "grad_norm": 0.33907508850097656,
      "learning_rate": 0.0001711791092598526,
      "loss": 0.1292,
      "step": 4800
    },
    {
      "epoch": 5.594516594516595,
      "grad_norm": 1.4261776208877563,
      "learning_rate": 0.00016717398269785325,
      "loss": 0.1313,
      "step": 4850
    },
    {
      "epoch": 5.6522366522366525,
      "grad_norm": 0.5464233160018921,
      "learning_rate": 0.00016316885613585388,
      "loss": 0.1326,
      "step": 4900
    },
    {
      "epoch": 5.70995670995671,
      "grad_norm": 1.3365615606307983,
      "learning_rate": 0.00015916372957385452,
      "loss": 0.1415,
      "step": 4950
    },
    {
      "epoch": 5.767676767676767,
      "grad_norm": 0.9100006818771362,
      "learning_rate": 0.00015515860301185518,
      "loss": 0.1376,
      "step": 5000
    },
    {
      "epoch": 5.825396825396825,
      "grad_norm": 0.9353777170181274,
      "learning_rate": 0.00015115347644985584,
      "loss": 0.1454,
      "step": 5050
    },
    {
      "epoch": 5.883116883116883,
      "grad_norm": 0.554063081741333,
      "learning_rate": 0.00014714834988785648,
      "loss": 0.1352,
      "step": 5100
    },
    {
      "epoch": 5.940836940836941,
      "grad_norm": 0.5168643593788147,
      "learning_rate": 0.0001431432233258571,
      "loss": 0.1378,
      "step": 5150
    },
    {
      "epoch": 5.998556998556999,
      "grad_norm": 0.4841287434101105,
      "learning_rate": 0.00013913809676385775,
      "loss": 0.1395,
      "step": 5200
    },
    {
      "epoch": 6.0,
      "eval_gleu": 86.63485416313397,
      "eval_loss": 0.8111575245857239,
      "eval_runtime": 30.9933,
      "eval_samples_per_second": 3.452,
      "eval_steps_per_second": 0.452,
      "step": 5202
    },
    {
      "epoch": 6.055411255411255,
      "grad_norm": 1.120456576347351,
      "learning_rate": 0.00013513297020185838,
      "loss": 0.1284,
      "step": 5250
    },
    {
      "epoch": 6.113131313131313,
      "grad_norm": 0.373990923166275,
      "learning_rate": 0.00013112784363985901,
      "loss": 0.1188,
      "step": 5300
    },
    {
      "epoch": 6.170851370851371,
      "grad_norm": 0.6062637567520142,
      "learning_rate": 0.00012712271707785965,
      "loss": 0.1236,
      "step": 5350
    },
    {
      "epoch": 6.228571428571429,
      "grad_norm": 0.53404301404953,
      "learning_rate": 0.0001231175905158603,
      "loss": 0.1217,
      "step": 5400
    },
    {
      "epoch": 6.2862914862914865,
      "grad_norm": 0.36190536618232727,
      "learning_rate": 0.00011911246395386093,
      "loss": 0.1372,
      "step": 5450
    },
    {
      "epoch": 6.344011544011544,
      "grad_norm": 0.4004152715206146,
      "learning_rate": 0.0001151073373918616,
      "loss": 0.1219,
      "step": 5500
    },
    {
      "epoch": 6.401731601731601,
      "grad_norm": 0.4627237319946289,
      "learning_rate": 0.00011110221082986223,
      "loss": 0.1339,
      "step": 5550
    },
    {
      "epoch": 6.459451659451659,
      "grad_norm": 0.3678419589996338,
      "learning_rate": 0.00010709708426786286,
      "loss": 0.1309,
      "step": 5600
    },
    {
      "epoch": 6.517171717171717,
      "grad_norm": 0.4394114911556244,
      "learning_rate": 0.00010309195770586351,
      "loss": 0.1313,
      "step": 5650
    },
    {
      "epoch": 6.574891774891775,
      "grad_norm": 0.48955997824668884,
      "learning_rate": 9.908683114386415e-05,
      "loss": 0.12,
      "step": 5700
    },
    {
      "epoch": 6.632611832611833,
      "grad_norm": 0.6780402064323425,
      "learning_rate": 9.508170458186478e-05,
      "loss": 0.1191,
      "step": 5750
    },
    {
      "epoch": 6.6903318903318905,
      "grad_norm": 0.5575729608535767,
      "learning_rate": 9.107657801986543e-05,
      "loss": 0.1272,
      "step": 5800
    },
    {
      "epoch": 6.748051948051948,
      "grad_norm": 0.3712775409221649,
      "learning_rate": 8.707145145786608e-05,
      "loss": 0.1217,
      "step": 5850
    },
    {
      "epoch": 6.805772005772006,
      "grad_norm": 0.5006951093673706,
      "learning_rate": 8.306632489586671e-05,
      "loss": 0.1305,
      "step": 5900
    },
    {
      "epoch": 6.863492063492064,
      "grad_norm": 0.3425583839416504,
      "learning_rate": 7.906119833386735e-05,
      "loss": 0.1259,
      "step": 5950
    },
    {
      "epoch": 6.921212121212121,
      "grad_norm": 0.3676530420780182,
      "learning_rate": 7.505607177186798e-05,
      "loss": 0.1263,
      "step": 6000
    },
    {
      "epoch": 6.978932178932179,
      "grad_norm": 0.33709466457366943,
      "learning_rate": 7.105094520986863e-05,
      "loss": 0.1257,
      "step": 6050
    },
    {
      "epoch": 7.0,
      "eval_gleu": 86.56490676914191,
      "eval_loss": 0.8485604524612427,
      "eval_runtime": 32.674,
      "eval_samples_per_second": 3.275,
      "eval_steps_per_second": 0.428,
      "step": 6069
    }
  ],
  "logging_steps": 50,
  "max_steps": 6936,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 4,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 1
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4831912956395520.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
